# Thursday, December 14, 2023
Comparing LLama2 performance on CPU and GPU using ollama.

[[LLM Inference Time]]

#LLM