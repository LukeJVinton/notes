# Thursday, February 1, 2024
- [x] Figure out how to cache upload to v db.
- [ ] Badly formatted doc names still in the vector database. Need to clean the database and reingest.
- [ ] Tool to remove documents from the study.
  - [ ] Button in doc viewer to remove doc from study? 
  - [ ] Removes file from list of study documents
  - [ ] If existing, removes analysis output from document
- [ ] Check for file existing and add stability for missing files in study.
  - [ ] document viewer
  - [ ] analyser
  - [ ] questioner
  - [ ] check for stability by testing with purposefully missing file.
- [ ] Tool in admin page to check all the documents in the vector database.
  - [ ] Compare with documents that are in the archive. If documents are in the db but not the archive then flag up.
  - [ ] Tool to remove particular document from the db
- [ ] GPU still running out of memory occasionally... Need way to protect against this. 
  - [ ] Seems to happen more for some papers, due to doc structure fand style leading to much larger chunks??
  - [ ] Text splitter uses `\n\n` by default, if this is not found the chunks can be much larger than the limit! 
    - [ ] Perhaps we should use a different seperator in case the document contains a lot of text before a double carriage return?
    - [ ] Use a fullstop and add in an overlap of say 50? 
- [ ] Stream response from LLM model?
- [ ] Work around for length of input on LLM. 
  - [ ] Less tokens per chunk? 
    - [ ] 2 chunks of 300 tokens?? 
  - [ ] Fewer chunks? 
- [ ] Webscraper - error when there have been too many requests:
`
webscraper  |   File "/usr/local/lib/python3.10/urllib/request.py", line 643, in http_error_default
webscraper  |     raise HTTPError(req.full_url, code, msg, hdrs, fp)
webscraper  | urllib.error.HTTPError: HTTP Error 429: Too Many Requests
`

- [ ] stability of application when components are unavailable. E.g. webscraper stopped working because of too many requests.

#vectordb
#webscraper
#urllib
#LLM
#streamlit
#forge
#experiment_day
#todo